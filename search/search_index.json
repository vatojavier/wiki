{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Wiki personal de Javi como la famosa DokuWiki de Juli\u00e1n but this is the Remix Si est\u00e1s aqu\u00ed es que est\u00e1s tramando algo. Aqu\u00ed me voy apuntando mis movidas.","title":"Introduction"},{"location":"#wiki-personal-de-javi-como-la-famosa-dokuwiki-de-julian-but-this-is-the-remix","text":"Si est\u00e1s aqu\u00ed es que est\u00e1s tramando algo. Aqu\u00ed me voy apuntando mis movidas.","title":"Wiki personal de Javi como la famosa DokuWiki de Juli\u00e1n but this is the Remix"},{"location":"a_zampar/comidas/arroz_pollo/","text":"Arroz con pollo Ingredientes 4 personas - Pollo - 2 Pimientos - 2 Cebollas - 3-4 Dientes de Ajo - 3-4 Tomates - 2 vasos de arroz - 4 vasos de caldo de pollo (pero seguramente habr\u00e1 que ir echando mas) - Azafr\u00e1n Procedimiento Meter pimientos, cebollas y ajo en cubitos junto con sal. Cocinar 5 mins hasta parcialmente blanda. Subir fuego y meter Pollo junto con sal y pimienta. Cocinar hasta pollo hecho. Meter Tomates en cubos. Cocinar 5 mins. Bajar a fuego medio y meter arroz. Remover todo 1 min. Echar doble de caldo que de arroz, Azafr\u00e1n y sal. Esperar que se haga el arroz 15-20 min e ir echando mas caldo/agua.","title":"Arroz con pollo"},{"location":"a_zampar/comidas/arroz_pollo/#arroz-con-pollo","text":"","title":"Arroz con pollo"},{"location":"a_zampar/comidas/arroz_pollo/#ingredientes-4-personas","text":"- Pollo - 2 Pimientos - 2 Cebollas - 3-4 Dientes de Ajo - 3-4 Tomates - 2 vasos de arroz - 4 vasos de caldo de pollo (pero seguramente habr\u00e1 que ir echando mas) - Azafr\u00e1n","title":"Ingredientes 4 personas"},{"location":"a_zampar/comidas/arroz_pollo/#procedimiento","text":"Meter pimientos, cebollas y ajo en cubitos junto con sal. Cocinar 5 mins hasta parcialmente blanda. Subir fuego y meter Pollo junto con sal y pimienta. Cocinar hasta pollo hecho. Meter Tomates en cubos. Cocinar 5 mins. Bajar a fuego medio y meter arroz. Remover todo 1 min. Echar doble de caldo que de arroz, Azafr\u00e1n y sal. Esperar que se haga el arroz 15-20 min e ir echando mas caldo/agua.","title":"Procedimiento"},{"location":"a_zampar/comidas/arroz_pollo_brocoli_oriental/","text":"Arroz con Pollo, brocoli y setas 2nd receta de este v\u00eddeo Ingredientes 3 personas - 3 o 4 Pechugas de pollo (en dados) - 3 o 4 setas grandes cortadas - 1 Brocoli cortado - 4 dientes de Ajo cortado - Gengibre misma cantidad que Ajo - 2 tsp Aceite de s\u00e9samo - 1/2 taza peque\u00f1a (de esas de cafe) de Salsa de soja bajo en sodio - 1 vaso Caldo de pollo - 1.5 tbsp Arina - Arroz Pasos Echar el pollo en dados a sarten y salpimentar, hasta hechos. Sacar pollo. Echar setas y mover un poco 1 minuto. Echar brocoli. Hacer setas y brocoli hasta que brocoli quede algo mas blando. Sacar todas las verduras. Hechar Ajo y Gengibre, cocinar un poco. Hechar Acite de s\u00e9samo, Salsa de soja, Caldo de pollo y Arina. Hacer hasta que espese. Hechar Pollo, Brocoli y Setas. Hacer y remover un poco m\u00e1s. Espabilar el arroz.","title":"Arroz Pollo con brocoli y setas"},{"location":"a_zampar/comidas/arroz_pollo_brocoli_oriental/#arroz-con-pollo-brocoli-y-setas","text":"2nd receta de este v\u00eddeo","title":"Arroz con Pollo, brocoli y setas"},{"location":"a_zampar/comidas/arroz_pollo_brocoli_oriental/#ingredientes-3-personas","text":"- 3 o 4 Pechugas de pollo (en dados) - 3 o 4 setas grandes cortadas - 1 Brocoli cortado - 4 dientes de Ajo cortado - Gengibre misma cantidad que Ajo - 2 tsp Aceite de s\u00e9samo - 1/2 taza peque\u00f1a (de esas de cafe) de Salsa de soja bajo en sodio - 1 vaso Caldo de pollo - 1.5 tbsp Arina - Arroz","title":"Ingredientes 3 personas"},{"location":"a_zampar/comidas/arroz_pollo_brocoli_oriental/#pasos","text":"Echar el pollo en dados a sarten y salpimentar, hasta hechos. Sacar pollo. Echar setas y mover un poco 1 minuto. Echar brocoli. Hacer setas y brocoli hasta que brocoli quede algo mas blando. Sacar todas las verduras. Hechar Ajo y Gengibre, cocinar un poco. Hechar Acite de s\u00e9samo, Salsa de soja, Caldo de pollo y Arina. Hacer hasta que espese. Hechar Pollo, Brocoli y Setas. Hacer y remover un poco m\u00e1s. Espabilar el arroz.","title":"Pasos"},{"location":"a_zampar/comidas/burritos/","text":"Burritos con carne picada Ingredientes 4 burritos - Carn\u00e9 picada vaca - Queso gratinado (cualquiera) - 1 Cebolla - Media taza de arroz - Passata o tomate frito - 2 dientes de Ajo - Jud\u00edas - Tomates - Lechuga - Yoghurt griego o Creme frache - Caldo de beef (opcional) - Maiz - Paprika, pepper, chili flakes, oregano Hacer arroz y mientras: Hacer onion hasta dorarlo. Meter ajo picao. Meter carne pic\u00e1 con (sal, comino, paprika, pepper, chili flakers, oregano). Cocinar hasta que no est\u00e9 rosa. Meter tomate (1 cucharada grande) Meter Beef stock (1/4 cup) Dejarlo 3- 4 min Sacar carne Poner en tortilla: arroz, la carne, maiz, jud\u00edas, lechuga, tomate cortado en trozos y queso gratinao) Poner Yoghurt Tostar burro en sart\u00e9n seca","title":"Burritos"},{"location":"a_zampar/comidas/burritos/#burritos-con-carne-picada","text":"","title":"Burritos con carne picada"},{"location":"a_zampar/comidas/burritos/#ingredientes-4-burritos","text":"- Carn\u00e9 picada vaca - Queso gratinado (cualquiera) - 1 Cebolla - Media taza de arroz - Passata o tomate frito - 2 dientes de Ajo - Jud\u00edas - Tomates - Lechuga - Yoghurt griego o Creme frache - Caldo de beef (opcional) - Maiz - Paprika, pepper, chili flakes, oregano Hacer arroz y mientras: Hacer onion hasta dorarlo. Meter ajo picao. Meter carne pic\u00e1 con (sal, comino, paprika, pepper, chili flakers, oregano). Cocinar hasta que no est\u00e9 rosa. Meter tomate (1 cucharada grande) Meter Beef stock (1/4 cup) Dejarlo 3- 4 min Sacar carne Poner en tortilla: arroz, la carne, maiz, jud\u00edas, lechuga, tomate cortado en trozos y queso gratinao) Poner Yoghurt Tostar burro en sart\u00e9n seca","title":"Ingredientes 4 burritos"},{"location":"a_zampar/comidas/chicken_butter/","text":"Chicken butter y arroz Video del jambo . Ingredientes 2 personas - 2 Pechugas o Muslos sin hueso (grandes) - Arroz - 300g-400g Passata (Tomate frito o picado) - Leche evaporada o cream (nata de cocinar creo) - Yoghurt griego - 1 Cebolla grande - 1-2 Quesitos o mantequilla pero mas gordura - Ajo Especias - Garam masala - Ajo en polvo - Paprika - C\u00farcuma (no importante) - Chili flakes o cayenne pepper algo picante - Pimienta Pasos Hacer Arroz y mientras Cortar pollo en trozos y echar en plato(no muy peque\u00f1os, 1 pollo grande en 4+-) Echar Sal y Garam masala (2 tsp) Echar 1.5 tbsp de Yoghurt Griego Remover todo y marinar x mins Meter pollos en sart\u00e9n a fuego alto y dorar los lados (no hace falta que se cocinen enteros) Sacar pollos Meter cebollas un poco blandas junto con especias: sal, garam masala, paprica, curcuma y el chili flaker Meter ajo Meter passata (como un vaso) y un culillo de agua, dejarlo unos minutos ah\u00ed Meter leche/crema y quesito/mantequilla Meter pollos y cocinar durante 7-8mins o hasta que se hagan por dentro","title":"Chicken butter"},{"location":"a_zampar/comidas/chicken_butter/#chicken-butter-y-arroz","text":"Video del jambo .","title":"Chicken butter y arroz"},{"location":"a_zampar/comidas/chicken_butter/#ingredientes-2-personas","text":"- 2 Pechugas o Muslos sin hueso (grandes) - Arroz - 300g-400g Passata (Tomate frito o picado) - Leche evaporada o cream (nata de cocinar creo) - Yoghurt griego - 1 Cebolla grande - 1-2 Quesitos o mantequilla pero mas gordura - Ajo Especias - Garam masala - Ajo en polvo - Paprika - C\u00farcuma (no importante) - Chili flakes o cayenne pepper algo picante - Pimienta","title":"Ingredientes 2 personas"},{"location":"a_zampar/comidas/chicken_butter/#pasos","text":"Hacer Arroz y mientras Cortar pollo en trozos y echar en plato(no muy peque\u00f1os, 1 pollo grande en 4+-) Echar Sal y Garam masala (2 tsp) Echar 1.5 tbsp de Yoghurt Griego Remover todo y marinar x mins Meter pollos en sart\u00e9n a fuego alto y dorar los lados (no hace falta que se cocinen enteros) Sacar pollos Meter cebollas un poco blandas junto con especias: sal, garam masala, paprica, curcuma y el chili flaker Meter ajo Meter passata (como un vaso) y un culillo de agua, dejarlo unos minutos ah\u00ed Meter leche/crema y quesito/mantequilla Meter pollos y cocinar durante 7-8mins o hasta que se hagan por dentro","title":"Pasos"},{"location":"a_zampar/comidas/crema_calabaza/","text":"Crema de calabaza Ingredientes 3 o 4 personas - 1 (500g) calabaza cacahuete - 1 Puerro - 1/2 Patata - 1 Cebolla - 3 Dientes de Ajo - Picatostes - 1 Caldo de verduras - 2 Quesitos - Pimienta Procedimiento En olla grande: poner en cubos no muy peque\u00f1os Puerro, Ajo y Cebolla hasta dorarlos. Meter calabaza y patatas cortados no muy peque\u00f1os y remover un poco. Meter agua caliente junto con Caldo de verduras. Esperar 20-25 minutos a fuego medio. Echar quesito y que se derrita unos minutos. Batir y echarle pimienta.","title":"Crema de calabaza"},{"location":"a_zampar/comidas/crema_calabaza/#crema-de-calabaza","text":"","title":"Crema de calabaza"},{"location":"a_zampar/comidas/crema_calabaza/#ingredientes-3-o-4-personas","text":"- 1 (500g) calabaza cacahuete - 1 Puerro - 1/2 Patata - 1 Cebolla - 3 Dientes de Ajo - Picatostes - 1 Caldo de verduras - 2 Quesitos - Pimienta","title":"Ingredientes 3 o 4 personas"},{"location":"a_zampar/comidas/crema_calabaza/#procedimiento","text":"En olla grande: poner en cubos no muy peque\u00f1os Puerro, Ajo y Cebolla hasta dorarlos. Meter calabaza y patatas cortados no muy peque\u00f1os y remover un poco. Meter agua caliente junto con Caldo de verduras. Esperar 20-25 minutos a fuego medio. Echar quesito y que se derrita unos minutos. Batir y echarle pimienta.","title":"Procedimiento"},{"location":"a_zampar/comidas/ensalada_cesar/","text":"Ensalada cesar - Pollo - Lechuga - Queso fresco - Tomate Hacer el pollo y meterlo a la ensalada","title":"Ensalada Cesar"},{"location":"a_zampar/comidas/ensalada_cesar/#ensalada-cesar","text":"- Pollo - Lechuga - Queso fresco - Tomate Hacer el pollo y meterlo a la ensalada","title":"Ensalada cesar"},{"location":"a_zampar/comidas/fajitas/","text":"Fajitas Ingredientes - Pollo - Pimientos - Cebolla - Sazonador de ese turbio Procedimiento Hacer pollo hasta que se dore, no hace falta hacerlos completamente. Sacar pollo Meter pimientos SAL y PIMIENTA hasta que se quede un poco blanda. Meter cebolla y el POLLO y un poco de SAL y SAZONAR junto con los pimientos hacerlo hasta que se quede la verdura blanda.","title":"Fajitas"},{"location":"a_zampar/comidas/fajitas/#fajitas","text":"","title":"Fajitas"},{"location":"a_zampar/comidas/fajitas/#ingredientes","text":"- Pollo - Pimientos - Cebolla - Sazonador de ese turbio","title":"Ingredientes"},{"location":"a_zampar/comidas/fajitas/#procedimiento","text":"Hacer pollo hasta que se dore, no hace falta hacerlos completamente. Sacar pollo Meter pimientos SAL y PIMIENTA hasta que se quede un poco blanda. Meter cebolla y el POLLO y un poco de SAL y SAZONAR junto con los pimientos hacerlo hasta que se quede la verdura blanda.","title":"Procedimiento"},{"location":"a_zampar/comidas/noodles_eggs_vegs/","text":"Noodles con huevos y vegetales Para 1 persona - Noodles - 1/2 Pimiento rojo - 2 Cebolletas - 2 Dientes de ajo - 1/2 chili - 1 Cebolla peque\u00f1a - 2 Huevos - Guisantes - Salsa soja - Vinagre de arroz - Probar a ponerle nueces Hacer Noodles y dejarlos por ah\u00ed. Echar veggies (cortados) en wok hasta un poco cocinado. Echar guisantes. Echar huevos en centro del wok y revolverlos con los vegs. Echar noodles, salsa de soja y vinagre de arroz y revolver.","title":"Noodles con huevo y vegetales"},{"location":"a_zampar/comidas/noodles_eggs_vegs/#noodles-con-huevos-y-vegetales","text":"Para 1 persona - Noodles - 1/2 Pimiento rojo - 2 Cebolletas - 2 Dientes de ajo - 1/2 chili - 1 Cebolla peque\u00f1a - 2 Huevos - Guisantes - Salsa soja - Vinagre de arroz - Probar a ponerle nueces Hacer Noodles y dejarlos por ah\u00ed. Echar veggies (cortados) en wok hasta un poco cocinado. Echar guisantes. Echar huevos en centro del wok y revolverlos con los vegs. Echar noodles, salsa de soja y vinagre de arroz y revolver.","title":"Noodles con huevos y vegetales"},{"location":"a_zampar/comidas/pasta_carbonara/","text":"Pasta carbonara potente 4 Pers: -Bacon en lonchas -Cebolla -Nata cocinar: 1 botes peqs -Leche evaporada: 1 botes peqs Hacer bacon sin que quede duro y sacar Hacer cebolla hasta blanda Meter nata y leche evaporada misma cantidad Meter bacon Ir haciendo la pasta Remover mazo","title":"Pasta carbonara"},{"location":"a_zampar/comidas/pasta_carbonara/#pasta-carbonara-potente","text":"4 Pers: -Bacon en lonchas -Cebolla -Nata cocinar: 1 botes peqs -Leche evaporada: 1 botes peqs Hacer bacon sin que quede duro y sacar Hacer cebolla hasta blanda Meter nata y leche evaporada misma cantidad Meter bacon Ir haciendo la pasta Remover mazo","title":"Pasta carbonara potente"},{"location":"a_zampar/comidas/pasta_feta/","text":"Pasta Feta Ingredientes 4 Personas - Pasta - Queso feta, 300g - Tomates cherry, 750g - Dientes de ajo, 4 - Chile 1/2 (opcional) - Albahaca (opcional) En bandeja de horno Poner un poco aceite en la bandeja. Meter Tomates, Ajos y Queso en el centro. Espolvorear Sal, Pimienta y Or\u00e9gano. Chorro de aceite por encima de todo. Meter al horno 200\u00ba 30 min. hasta que tomates blandos Hacer pasta Mezclar todo aplastando tomates y echar la pasta.","title":"Pasta Feta"},{"location":"a_zampar/comidas/pasta_feta/#pasta-feta","text":"","title":"Pasta Feta"},{"location":"a_zampar/comidas/pasta_feta/#ingredientes","text":"4 Personas - Pasta - Queso feta, 300g - Tomates cherry, 750g - Dientes de ajo, 4 - Chile 1/2 (opcional) - Albahaca (opcional) En bandeja de horno Poner un poco aceite en la bandeja. Meter Tomates, Ajos y Queso en el centro. Espolvorear Sal, Pimienta y Or\u00e9gano. Chorro de aceite por encima de todo. Meter al horno 200\u00ba 30 min. hasta que tomates blandos Hacer pasta Mezclar todo aplastando tomates y echar la pasta.","title":"Ingredientes"},{"location":"a_zampar/comidas/pollo_agridulce/","text":"Pollo agridulce oriental potente \u2570( \u00b0\u25bd\u00b0 )\u256f Link del gorka Ponerle arroz pls.","title":"Pollo agridulce"},{"location":"a_zampar/comidas/pollo_agridulce/#pollo-agridulce-oriental-potente","text":"Link del gorka Ponerle arroz pls.","title":"Pollo agridulce oriental potente \u2570(\u00b0\u25bd\u00b0)\u256f"},{"location":"a_zampar/postres/protein_cake/","text":"Tarta de protes 60g oats - blend it 1 Egg 1/2 Teaspoonful baking powder 1/2 Teaspoonful vanilla extract 100ml milk 1 Medium banana 1 Oz Whey protein Blend it Add it to a greasaed baking dish Put it in a microwave for almost 3 minutes Poner toppings","title":"Protein cake"},{"location":"a_zampar/postres/protein_cake/#tarta-de-protes","text":"60g oats - blend it 1 Egg 1/2 Teaspoonful baking powder 1/2 Teaspoonful vanilla extract 100ml milk 1 Medium banana 1 Oz Whey protein Blend it Add it to a greasaed baking dish Put it in a microwave for almost 3 minutes Poner toppings","title":"Tarta de protes"},{"location":"informatica/informatica/","text":"Movidas de inform\u00e1tica","title":"Informatica"},{"location":"informatica/informatica/#movidas-de-informatica","text":"","title":"Movidas de inform\u00e1tica"},{"location":"informatica/BBDD/MySQL/","text":"COUNT con condici\u00f3n sin utilizar un WHERE SELECT sum ( if ( t . cost_premium_insurance > 0 , 1 , 0 )) as viajesConSeguro FROM TABLA_WAPA Condici\u00f3n de columna en where Dependiendo de alg\u00fan campo, la condici\u00f3n del where puede depender de una columna u otra: Solo meter un case en el where con la condici\u00f3n y seleccionando la columna select * from TABLAS_Y_JOINS WHERE ( case when refund_id is null and gc . payment_id is not null then pa . created_at when refund_id is null and gc . payment_id is null then gc . created_at WHEN refund_id is not null then pa2 . created_at end ) >= '{start_date}' Show processes and kill them SHOW PROCESSLIST ; KILL 38239 ; KILL 38240 ; -- To make it more automatically SELECT concat ( 'KILL ' , id , ';' ) FROM information_schema . processlist ; -- And execute the output one by one Match bits Match bit position, useful when there is info by bit level (i.e user inactive reasons: bit 0 = reason x, bit 1 = reason y ...) SELECT * FROM User u WHERE CONVERT ( inactive_reason USING BINARY ) & 1 << 17 > 0 -- check if bit at 17th position is 1","title":"MySQL"},{"location":"informatica/BBDD/MySQL/#count-con-condicion-sin-utilizar-un-where","text":"SELECT sum ( if ( t . cost_premium_insurance > 0 , 1 , 0 )) as viajesConSeguro FROM TABLA_WAPA","title":"COUNT con condici\u00f3n sin utilizar un WHERE"},{"location":"informatica/BBDD/MySQL/#condicion-de-columna-en-where","text":"Dependiendo de alg\u00fan campo, la condici\u00f3n del where puede depender de una columna u otra: Solo meter un case en el where con la condici\u00f3n y seleccionando la columna select * from TABLAS_Y_JOINS WHERE ( case when refund_id is null and gc . payment_id is not null then pa . created_at when refund_id is null and gc . payment_id is null then gc . created_at WHEN refund_id is not null then pa2 . created_at end ) >= '{start_date}'","title":"Condici\u00f3n de columna en where"},{"location":"informatica/BBDD/MySQL/#show-processes-and-kill-them","text":"SHOW PROCESSLIST ; KILL 38239 ; KILL 38240 ; -- To make it more automatically SELECT concat ( 'KILL ' , id , ';' ) FROM information_schema . processlist ; -- And execute the output one by one","title":"Show processes and kill them"},{"location":"informatica/BBDD/MySQL/#match-bits","text":"Match bit position, useful when there is info by bit level (i.e user inactive reasons: bit 0 = reason x, bit 1 = reason y ...) SELECT * FROM User u WHERE CONVERT ( inactive_reason USING BINARY ) & 1 << 17 > 0 -- check if bit at 17th position is 1","title":"Match bits"},{"location":"informatica/BBDD/Postgres/","text":"Postgres Despu\u00e9s de instalarlo como dice la p\u00e1gina puede dar el error: psql: error: FATAL: Peer authentication failed for user \"postgres\" Entonces cambiar la linea del archivo /etc/postgresql/13/main/pg_hba.conf de local all postgres peer a local all postgres md5 psql Lista las DB psql -U postgres -l Comandos dentro de psql Listar DBs: \\l Listar usuarios: \\du Conectar a DB: \\c database Listar tablas de esa DB: \\dt","title":"PostgreSQL"},{"location":"informatica/BBDD/Postgres/#postgres","text":"Despu\u00e9s de instalarlo como dice la p\u00e1gina puede dar el error: psql: error: FATAL: Peer authentication failed for user \"postgres\" Entonces cambiar la linea del archivo /etc/postgresql/13/main/pg_hba.conf de local all postgres peer a local all postgres md5","title":"Postgres"},{"location":"informatica/BBDD/Postgres/#psql","text":"","title":"psql"},{"location":"informatica/BBDD/Postgres/#lista-las-db","text":"psql -U postgres -l","title":"Lista las DB"},{"location":"informatica/BBDD/Postgres/#comandos-dentro-de-psql","text":"Listar DBs: \\l Listar usuarios: \\du Conectar a DB: \\c database Listar tablas de esa DB: \\dt","title":"Comandos dentro de psql"},{"location":"informatica/bash/bash/","text":"Useful Bash commands sed Change files content sed -i 's/search_string/replace_string/' filenames \u2018-i\u2019 option is used to modify the content of the original file with the replacement string if the search string exists in the file. Make a backup copy with -i.bak and will create a copy with .bak extension \u2018s\u2019 indicates the substitute command. SSH Connect to remote host to stablish proxy in your machine ssh -L <port_in_your_machine>:<remote_private_internal_ip>:<remote_port> -i /path/to/private_key user@<remote_public_ip> -N Example remote connection to MySQL ssh -L 33061:remote_internal_ip:3306 -i ~/keys/key elvato@ip -N","title":"Bash"},{"location":"informatica/bash/bash/#useful-bash-commands","text":"","title":"Useful Bash commands"},{"location":"informatica/bash/bash/#sed","text":"","title":"sed"},{"location":"informatica/bash/bash/#change-files-content","text":"sed -i 's/search_string/replace_string/' filenames \u2018-i\u2019 option is used to modify the content of the original file with the replacement string if the search string exists in the file. Make a backup copy with -i.bak and will create a copy with .bak extension \u2018s\u2019 indicates the substitute command.","title":"Change files content"},{"location":"informatica/bash/bash/#ssh","text":"","title":"SSH"},{"location":"informatica/bash/bash/#connect-to-remote-host-to-stablish-proxy-in-your-machine","text":"ssh -L <port_in_your_machine>:<remote_private_internal_ip>:<remote_port> -i /path/to/private_key user@<remote_public_ip> -N Example remote connection to MySQL ssh -L 33061:remote_internal_ip:3306 -i ~/keys/key elvato@ip -N","title":"Connect to remote host to stablish proxy in your machine"},{"location":"informatica/control_versiones/git/","text":"Git Start a git repo from existing files Create GitHub repo without README Go to the directory with the stuff git init -b main git add . git commit -m \"Project started\" git remote add origin <REMOTE_URL> git push origin main Ramas Crear: git branch nombre_rama Cambiar a: git checkout nombre_rama Combinar crear y cambiar: git checkout -b nombre_rama Merge Mergea la rama que digas -> en la que est\u00e1s feature/feature_mazo_wapo -> develop git checkout develop git merge feature/feature_mazo_wapo Rebase Incluye los cambio de otra rama en la tuya, \"la rebasa\". Est\u00e1s en rama feature/cosa_wapa y has hecho alg\u00fan cambio directo en la rama develop por cualquier movida o esque eres imb\u00e9cil: En la rama feature/cosa_wapa A---B---C feature/cosa_wapa / D---E---F---G develop git rebase develop A'--B'--C' feature/cosa_wapa / D---E---F---G develop Grep -ni muestra la linea con enlace git grep -n \"cosa_interesante\" Autorizar SSH Puede dar el error git@github.com: Permission denied (publickey)... Seguir los pasos de generate, add y SAML (para organizaci\u00f3n) GitHub Take some changes from other commit git checkout <commit hash> -p file.py takes changes by hunks from hash commit to file.py, y to apply them.","title":"GIT"},{"location":"informatica/control_versiones/git/#git","text":"","title":"Git"},{"location":"informatica/control_versiones/git/#start-a-git-repo-from-existing-files","text":"Create GitHub repo without README Go to the directory with the stuff git init -b main git add . git commit -m \"Project started\" git remote add origin <REMOTE_URL> git push origin main","title":"Start a git repo from existing files"},{"location":"informatica/control_versiones/git/#ramas","text":"Crear: git branch nombre_rama Cambiar a: git checkout nombre_rama Combinar crear y cambiar: git checkout -b nombre_rama","title":"Ramas"},{"location":"informatica/control_versiones/git/#merge","text":"Mergea la rama que digas -> en la que est\u00e1s feature/feature_mazo_wapo -> develop git checkout develop git merge feature/feature_mazo_wapo","title":"Merge"},{"location":"informatica/control_versiones/git/#rebase","text":"Incluye los cambio de otra rama en la tuya, \"la rebasa\". Est\u00e1s en rama feature/cosa_wapa y has hecho alg\u00fan cambio directo en la rama develop por cualquier movida o esque eres imb\u00e9cil: En la rama feature/cosa_wapa A---B---C feature/cosa_wapa / D---E---F---G develop git rebase develop A'--B'--C' feature/cosa_wapa / D---E---F---G develop","title":"Rebase"},{"location":"informatica/control_versiones/git/#grep","text":"-ni muestra la linea con enlace git grep -n \"cosa_interesante\"","title":"Grep"},{"location":"informatica/control_versiones/git/#autorizar-ssh","text":"Puede dar el error git@github.com: Permission denied (publickey)... Seguir los pasos de generate, add y SAML (para organizaci\u00f3n) GitHub","title":"Autorizar SSH"},{"location":"informatica/control_versiones/git/#take-some-changes-from-other-commit","text":"git checkout <commit hash> -p file.py takes changes by hunks from hash commit to file.py, y to apply them.","title":"Take some changes from other commit"},{"location":"informatica/docker/docker/","text":"Docker Ejemplo desplegar y ejecutar una aplicaci\u00f3n con Docker: Dockerfile Tener un Dockerfile y un requirements.txt . ENTRYPOINT ser\u00e1 el comando a ejecutar cuando se eejecute el Docker. Dockerfile FROM python:3.8-slim-buster RUN apt-get update && apt-get upgrade -y && rm -rf /var/lib/apt/lists/* RUN pip install pip --upgrade RUN mkdir /app RUN mkdir /app/logs COPY . /app/ WORKDIR /app RUN pip install -r requirements.txt WORKDIR /app ENTRYPOINT [ \"python\" , \"send_mail.py\" ] Desplegar deployMail.sh cd /home/elvato # O si quieres desde un repo de git #cd /GIT/aad_datascience__reporte-diario #git fetch --all #git reset --hard origin/develop #git pull origin develop docker build -t reporte-mail:1.0 . Ejecutar executeMail.sh #!/bin/bash docker rm -f reporte-mail docker run \\ --name reporte-mail \\ -e VAR1 = \"VAR1\" \\ -e \"VAR2=VAR2\" \\ -e \"LOGS_PATH=/app/logs\" \\ -v /var/log/reporte-mail/:/app/logs \\ reporte-mail:1.0 > /home/elvato/log.txt","title":"Docker"},{"location":"informatica/docker/docker/#docker","text":"Ejemplo desplegar y ejecutar una aplicaci\u00f3n con Docker:","title":"Docker"},{"location":"informatica/docker/docker/#dockerfile","text":"Tener un Dockerfile y un requirements.txt . ENTRYPOINT ser\u00e1 el comando a ejecutar cuando se eejecute el Docker. Dockerfile FROM python:3.8-slim-buster RUN apt-get update && apt-get upgrade -y && rm -rf /var/lib/apt/lists/* RUN pip install pip --upgrade RUN mkdir /app RUN mkdir /app/logs COPY . /app/ WORKDIR /app RUN pip install -r requirements.txt WORKDIR /app ENTRYPOINT [ \"python\" , \"send_mail.py\" ]","title":"Dockerfile"},{"location":"informatica/docker/docker/#desplegar","text":"deployMail.sh cd /home/elvato # O si quieres desde un repo de git #cd /GIT/aad_datascience__reporte-diario #git fetch --all #git reset --hard origin/develop #git pull origin develop docker build -t reporte-mail:1.0 .","title":"Desplegar"},{"location":"informatica/docker/docker/#ejecutar","text":"executeMail.sh #!/bin/bash docker rm -f reporte-mail docker run \\ --name reporte-mail \\ -e VAR1 = \"VAR1\" \\ -e \"VAR2=VAR2\" \\ -e \"LOGS_PATH=/app/logs\" \\ -v /var/log/reporte-mail/:/app/logs \\ reporte-mail:1.0 > /home/elvato/log.txt","title":"Ejecutar"},{"location":"informatica/editores/jupyter/","text":"Jupyter Notebook Crear Kernel Crear kernel para poder cambiar de entorno on the fly En el entorno virtual que quieres a\u00f1adir: pip install ipython pip install tornado ipykernel ipython kernel install --user --name=kernelname Y para borrarlo jupyter kernelspec uninstall kernelname","title":"Jupyter"},{"location":"informatica/editores/jupyter/#jupyter-notebook","text":"","title":"Jupyter Notebook"},{"location":"informatica/editores/jupyter/#crear-kernel","text":"Crear kernel para poder cambiar de entorno on the fly En el entorno virtual que quieres a\u00f1adir: pip install ipython pip install tornado ipykernel ipython kernel install --user --name=kernelname Y para borrarlo jupyter kernelspec uninstall kernelname","title":"Crear Kernel"},{"location":"informatica/editores/vscode/","text":"VSCode Comando abrir acciones Ctrl + shift + p Workspace Para tener abiertos distintos repos a la vez y no reiniciar el VSCode Crear archivo nombre_cualquiera.code-workspace con { \"folders\":[ { \"name\":\"nombre_repo_1\", \"path\":\"realitve/path/to/repo_1\" }, { \"name\":\"nombre_repo_2\", \"path\":\"realitve/path/to/repo_2\" }, ] } Cursor movement Go back to previous loc: Ctrl Alt - Go forward loc: Ctrl Shift - VIM VSCode Go beggining of file: gg Go end of file: G Replace stuff, use \\ to scape special characters :%s/foo/bar/g Replace stuff in selection: :'<,'>s/foo/bar/g Select word under cursor: viw Cursor: Go to function definition: ctr+] Go back: ctrl+o Go forth: ctrl+i Replace with groups: %s/\\(.*\\)=\\(.*\\)/export \\1=\\2/g Embrace groups with \\(\\) and use them with \\1 , \\2 ... Example replace POSTGRES_DB=postgres with export POSTGRES_DB=postgres","title":"VSCode"},{"location":"informatica/editores/vscode/#vscode","text":"","title":"VSCode"},{"location":"informatica/editores/vscode/#comando-abrir-acciones","text":"Ctrl + shift + p","title":"Comando abrir acciones"},{"location":"informatica/editores/vscode/#workspace","text":"Para tener abiertos distintos repos a la vez y no reiniciar el VSCode Crear archivo nombre_cualquiera.code-workspace con { \"folders\":[ { \"name\":\"nombre_repo_1\", \"path\":\"realitve/path/to/repo_1\" }, { \"name\":\"nombre_repo_2\", \"path\":\"realitve/path/to/repo_2\" }, ] }","title":"Workspace"},{"location":"informatica/editores/vscode/#cursor-movement","text":"Go back to previous loc: Ctrl Alt - Go forward loc: Ctrl Shift -","title":"Cursor movement"},{"location":"informatica/editores/vscode/#vim-vscode","text":"Go beggining of file: gg Go end of file: G Replace stuff, use \\ to scape special characters :%s/foo/bar/g Replace stuff in selection: :'<,'>s/foo/bar/g Select word under cursor: viw","title":"VIM VSCode"},{"location":"informatica/editores/vscode/#cursor","text":"Go to function definition: ctr+] Go back: ctrl+o Go forth: ctrl+i","title":"Cursor:"},{"location":"informatica/editores/vscode/#replace-with-groups","text":"%s/\\(.*\\)=\\(.*\\)/export \\1=\\2/g Embrace groups with \\(\\) and use them with \\1 , \\2 ... Example replace POSTGRES_DB=postgres with export POSTGRES_DB=postgres","title":"Replace with groups:"},{"location":"informatica/entornos/anaconda/","text":"Anaconda","title":"Anaconda"},{"location":"informatica/entornos/anaconda/#anaconda","text":"","title":"Anaconda"},{"location":"informatica/flutter/flutter/","text":"Vainas de flutter Widgets with paramaters With positional arguments CustomInputField(\"LMAO\", Icons.lock, we, true) class CustomInputField extends StatelessWidget { const CustomInputField ( this . hintText , this . icon , this . mediaWidth , this . isPassword , { Key ? key , }) : super ( key: key ); final String hintText ; final IconData icon ; final num mediaWidth ; final bool isPassword ; // ... } Or with \"named\" arguments: CustomInputFieldNamed(hintText: \"LMAO\", icon: Icons.lock, mediaWidth: we) class CustomInputFieldNamed extends StatelessWidget { const CustomInputFieldNamed ({ Key ? key , required this . hintText , required this . icon , required this . mediaWidth , }) : super ( key: key ); final String hintText ; final IconData icon ; final num mediaWidth ; // ... } Async call using FutureBuilder when pressing a button Insert this widget into a widget or whatever. Just remember to call the foking setState() method // Esta vaina contiene el futureBuilder class MyFutureStatefulWidget extends StatefulWidget { const MyFutureStatefulWidget ({ Key ? key }) : super ( key: key ); @override _MyFutureStatefulWidgetState createState () => _MyFutureStatefulWidgetState (); } class _MyFutureStatefulWidgetState extends State < MyFutureStatefulWidget > { Future < String >? _result ; Future < String > computate (){ return Future < String > . delayed ( const Duration ( seconds: 1 ), () => 'Data Loaded!!!' , ); } void asignar (){ setState (() { _result = computate (); }); } @override Widget build ( BuildContext context ) { return FutureBuilder < String > ( future: _result , builder: ( BuildContext context , AsyncSnapshot < String > snapshot ) { List < Widget > children ; if ( snapshot . hasData ){ children = < Widget > [ const Icon ( Icons . check_circle_outline , color: Colors . green , size: 60 , ), Padding ( padding: const EdgeInsets . only ( top: 16 ), child: Text ( 'Result: ${ snapshot . data } ' ), ) ]; } else if ( snapshot . hasError ){ children = < Widget > [ const Icon ( Icons . error_outline , color: Colors . red , size: 60 , ), Padding ( padding: const EdgeInsets . only ( top: 16 ), child: Text ( 'Error: ${ snapshot . error } ' ), ) ]; } else { children = < Widget > [ const SizedBox ( child: CircularProgressIndicator (), width: 60 , height: 60 , ), const Padding ( padding: EdgeInsets . only ( top: 16 ), child: Text ( 'Awaiting result...' ), ), ElevatedButton ( onPressed: () => asignar (), child: Text ( 'Calculate' ) ), ]; } return Center ( child: Column ( mainAxisAlignment: MainAxisAlignment . center , crossAxisAlignment: CrossAxisAlignment . center , children: children , ), ); }, ); } }","title":"Flutter"},{"location":"informatica/flutter/flutter/#vainas-de-flutter","text":"","title":"Vainas de flutter"},{"location":"informatica/flutter/flutter/#widgets-with-paramaters","text":"With positional arguments CustomInputField(\"LMAO\", Icons.lock, we, true) class CustomInputField extends StatelessWidget { const CustomInputField ( this . hintText , this . icon , this . mediaWidth , this . isPassword , { Key ? key , }) : super ( key: key ); final String hintText ; final IconData icon ; final num mediaWidth ; final bool isPassword ; // ... } Or with \"named\" arguments: CustomInputFieldNamed(hintText: \"LMAO\", icon: Icons.lock, mediaWidth: we) class CustomInputFieldNamed extends StatelessWidget { const CustomInputFieldNamed ({ Key ? key , required this . hintText , required this . icon , required this . mediaWidth , }) : super ( key: key ); final String hintText ; final IconData icon ; final num mediaWidth ; // ... }","title":"Widgets with paramaters"},{"location":"informatica/flutter/flutter/#async-call-using-futurebuilder-when-pressing-a-button","text":"Insert this widget into a widget or whatever. Just remember to call the foking setState() method // Esta vaina contiene el futureBuilder class MyFutureStatefulWidget extends StatefulWidget { const MyFutureStatefulWidget ({ Key ? key }) : super ( key: key ); @override _MyFutureStatefulWidgetState createState () => _MyFutureStatefulWidgetState (); } class _MyFutureStatefulWidgetState extends State < MyFutureStatefulWidget > { Future < String >? _result ; Future < String > computate (){ return Future < String > . delayed ( const Duration ( seconds: 1 ), () => 'Data Loaded!!!' , ); } void asignar (){ setState (() { _result = computate (); }); } @override Widget build ( BuildContext context ) { return FutureBuilder < String > ( future: _result , builder: ( BuildContext context , AsyncSnapshot < String > snapshot ) { List < Widget > children ; if ( snapshot . hasData ){ children = < Widget > [ const Icon ( Icons . check_circle_outline , color: Colors . green , size: 60 , ), Padding ( padding: const EdgeInsets . only ( top: 16 ), child: Text ( 'Result: ${ snapshot . data } ' ), ) ]; } else if ( snapshot . hasError ){ children = < Widget > [ const Icon ( Icons . error_outline , color: Colors . red , size: 60 , ), Padding ( padding: const EdgeInsets . only ( top: 16 ), child: Text ( 'Error: ${ snapshot . error } ' ), ) ]; } else { children = < Widget > [ const SizedBox ( child: CircularProgressIndicator (), width: 60 , height: 60 , ), const Padding ( padding: EdgeInsets . only ( top: 16 ), child: Text ( 'Awaiting result...' ), ), ElevatedButton ( onPressed: () => asignar (), child: Text ( 'Calculate' ) ), ]; } return Center ( child: Column ( mainAxisAlignment: MainAxisAlignment . center , crossAxisAlignment: CrossAxisAlignment . center , children: children , ), ); }, ); } }","title":"Async call using FutureBuilder when pressing a button"},{"location":"informatica/js/js/","text":"JavaScript Async functions with Ajax HTTP request // Request functions must be async async function getLastScoringUpdate (){ var response = await $ . ajax ({ url : '/maps/last_scoring_update' , contentType : 'application/json' , // more settings }); // Inside this function, the code will stop till the response is given console . log ( response . last_update ); $ ( \"#map_last_update\" ). text ( \"\u00daltima actualizaci\u00f3n: \" + response . last_update ); return await response . last_update } // When calling it, the code outside won't stop, but can catch actions when response given with .then() getLastScoringUpdate (). then ( fecha => initDatePicker ( new Date ( fecha ), new Date ( fecha ))) // Code here may be executed before getting a response Mostrar elemento que ya est\u00e1 en \"hidden\"=true $ ( \"#id-del-div\" ). attr ( \"hidden\" , false );","title":"General"},{"location":"informatica/js/js/#javascript","text":"","title":"JavaScript"},{"location":"informatica/js/js/#async-functions-with-ajax-http-request","text":"// Request functions must be async async function getLastScoringUpdate (){ var response = await $ . ajax ({ url : '/maps/last_scoring_update' , contentType : 'application/json' , // more settings }); // Inside this function, the code will stop till the response is given console . log ( response . last_update ); $ ( \"#map_last_update\" ). text ( \"\u00daltima actualizaci\u00f3n: \" + response . last_update ); return await response . last_update } // When calling it, the code outside won't stop, but can catch actions when response given with .then() getLastScoringUpdate (). then ( fecha => initDatePicker ( new Date ( fecha ), new Date ( fecha ))) // Code here may be executed before getting a response","title":"Async functions with Ajax HTTP request"},{"location":"informatica/js/js/#mostrar-elemento-que-ya-esta-en-hiddentrue","text":"$ ( \"#id-del-div\" ). attr ( \"hidden\" , false );","title":"Mostrar elemento que ya est\u00e1 en \"hidden\"=true"},{"location":"informatica/kotlin/kotlin/","text":"Kotlin Databinding Te permite acceder a todos los recursos del layout sin tener que hacer findViewById() Activar DataBinding en el build.graddle (app): android{ ... buildFeatures{ dataBinding = true } } Envolver ficher de dise\u00f1o de actividad/fragmento en un <layout> : <layout xmlns:android= \"http://schemas.android.com/apk/res/android\" xmlns:tools= \"http://schemas.android.com/tools\" > <LinearLayout android:id= \"@+id/main\" android:layout_width= \"match_parent\" android:layout_height= \"match_parent\" ... Declarar e inicializar el objeto binding: Si es una actividad se inicializa en onCreate(): class MainActivity : AppCompatActivity () { lateinit var binding : ActivityMainBinding ... override fun onCreate ( savedInstanceState : Bundle?) { super . onCreate ( savedInstanceState ) binding = DataBindingUtil . setContentView ( this , R . layout . activity_main ) binding . generateButton . setOnClickListener { viewModel . generateNumber ()} } Si es un fragmento se hace en OnCreateView(): class MainFragment : Fragment () { lateinit var binding : FragmentMainBinding override fun onCreateView ( inflater : LayoutInflater , container : ViewGroup?, savedInstanceState : Bundle? ): View { binding = DataBindingUtil . inflate < FragmentMainBinding > ( inflater , R . layout . fragment_main , container , false ) return binding . root // Y ya se puede usar jaujas } Comparar fragments en un FrameLayout Teniendo MainFragment como una clase que hereda de Fragment() var fragment = supportFragmentManager . findFragmentById ( R . id . container ) // Id del frame que aloja al fragmen if ( fragment is MainFragment ){ // Hacer movidas } Si no va algo, meter los dise\u00f1os en un <layout> y espabilando. RoomDatabse con ViewModel y LiveData Cuando se hace una query, se hace de forma async por lo que es necesario que esta devuelva un LiveData para que cuando se reciba el resultado se pueda realizar alguna acci\u00f3n (actualizar el UI o asignar otros valores etc). Ejemplo actualizar valor con query: viewModel: class StatisticsViewModel ( application : Application ): AndroidViewModel ( application ) { private val context = getApplication < Application > (). applicationContext // Las queries devuelven un LiveData<Int> val nEasy = CardDatabase . getInstance ( context ). cardDao . getNEasyCards () val nDoubt = CardDatabase . getInstance ( context ). cardDao . getNDoubtCards () val nHard = CardDatabase . getInstance ( context ). cardDao . getNHardCards () } fragmet: class StatisticsFragment : Fragment () { private val statisticsViewModel : StatisticsViewModel by lazy { ViewModelProvider ( this ). get ( StatisticsViewModel :: class . java ) } override fun onCreateView ( inflater : LayoutInflater , container : ViewGroup?, savedInstanceState : Bundle? ): View? { binding = DataBindingUtil . inflate ( inflater , R . layout . fragment_statistics , container , false ) var easy = 0 var doubt = 0 var hard = 0 statisticsViewModel . apply { nEasy . observe ( viewLifecycleOwner , Observer { easy = it // Es aqu\u00ed cuando se completa la query y se actualiza el valor } ) nDoubt . observe ( viewLifecycleOwner , Observer { doubt = it // Es aqu\u00ed cuando se completa la query y se actualiza el valor } ) nHard . observe ( viewLifecycleOwner , Observer { hard = it // Es aqu\u00ed cuando se completa la query y se actualiza el valor } ) } // Aqu\u00ed, easy, doubt y hard pueden ser 0 u el valor de la query dependiendo de si ha llegao a completarse la query return binding . root }","title":"General"},{"location":"informatica/kotlin/kotlin/#kotlin","text":"","title":"Kotlin"},{"location":"informatica/kotlin/kotlin/#databinding","text":"Te permite acceder a todos los recursos del layout sin tener que hacer findViewById() Activar DataBinding en el build.graddle (app): android{ ... buildFeatures{ dataBinding = true } } Envolver ficher de dise\u00f1o de actividad/fragmento en un <layout> : <layout xmlns:android= \"http://schemas.android.com/apk/res/android\" xmlns:tools= \"http://schemas.android.com/tools\" > <LinearLayout android:id= \"@+id/main\" android:layout_width= \"match_parent\" android:layout_height= \"match_parent\" ... Declarar e inicializar el objeto binding: Si es una actividad se inicializa en onCreate(): class MainActivity : AppCompatActivity () { lateinit var binding : ActivityMainBinding ... override fun onCreate ( savedInstanceState : Bundle?) { super . onCreate ( savedInstanceState ) binding = DataBindingUtil . setContentView ( this , R . layout . activity_main ) binding . generateButton . setOnClickListener { viewModel . generateNumber ()} } Si es un fragmento se hace en OnCreateView(): class MainFragment : Fragment () { lateinit var binding : FragmentMainBinding override fun onCreateView ( inflater : LayoutInflater , container : ViewGroup?, savedInstanceState : Bundle? ): View { binding = DataBindingUtil . inflate < FragmentMainBinding > ( inflater , R . layout . fragment_main , container , false ) return binding . root // Y ya se puede usar jaujas }","title":"Databinding"},{"location":"informatica/kotlin/kotlin/#comparar-fragments-en-un-framelayout","text":"Teniendo MainFragment como una clase que hereda de Fragment() var fragment = supportFragmentManager . findFragmentById ( R . id . container ) // Id del frame que aloja al fragmen if ( fragment is MainFragment ){ // Hacer movidas } Si no va algo, meter los dise\u00f1os en un <layout> y espabilando.","title":"Comparar fragments en un FrameLayout"},{"location":"informatica/kotlin/kotlin/#roomdatabse-con-viewmodel-y-livedata","text":"Cuando se hace una query, se hace de forma async por lo que es necesario que esta devuelva un LiveData para que cuando se reciba el resultado se pueda realizar alguna acci\u00f3n (actualizar el UI o asignar otros valores etc). Ejemplo actualizar valor con query: viewModel: class StatisticsViewModel ( application : Application ): AndroidViewModel ( application ) { private val context = getApplication < Application > (). applicationContext // Las queries devuelven un LiveData<Int> val nEasy = CardDatabase . getInstance ( context ). cardDao . getNEasyCards () val nDoubt = CardDatabase . getInstance ( context ). cardDao . getNDoubtCards () val nHard = CardDatabase . getInstance ( context ). cardDao . getNHardCards () } fragmet: class StatisticsFragment : Fragment () { private val statisticsViewModel : StatisticsViewModel by lazy { ViewModelProvider ( this ). get ( StatisticsViewModel :: class . java ) } override fun onCreateView ( inflater : LayoutInflater , container : ViewGroup?, savedInstanceState : Bundle? ): View? { binding = DataBindingUtil . inflate ( inflater , R . layout . fragment_statistics , container , false ) var easy = 0 var doubt = 0 var hard = 0 statisticsViewModel . apply { nEasy . observe ( viewLifecycleOwner , Observer { easy = it // Es aqu\u00ed cuando se completa la query y se actualiza el valor } ) nDoubt . observe ( viewLifecycleOwner , Observer { doubt = it // Es aqu\u00ed cuando se completa la query y se actualiza el valor } ) nHard . observe ( viewLifecycleOwner , Observer { hard = it // Es aqu\u00ed cuando se completa la query y se actualiza el valor } ) } // Aqu\u00ed, easy, doubt y hard pueden ser 0 u el valor de la query dependiendo de si ha llegao a completarse la query return binding . root }","title":"RoomDatabse con ViewModel y LiveData"},{"location":"informatica/linux/linux/","text":"Linux Add to PATH Permite ejecutar programas, que est\u00e9n en el directorio que a\u00f1adas, desde cualquier sitio. Editar /home/usuario/.profile y a\u00f1adir al final export PATH=$PATH:/path/to/dir Reiniciar la terminal o ejecutar source .profile Crontabs crontab -l see. crontab -e edit. sudo crontab -u <username> -l other user's crontab. Ubuntu Create executable for the Ubuntu UI. Te lo encontrar\u00e1 el sistema y poder ejecutarlo con su icono y tal. Crear un archivo en /usr/share/applications y llamarlo mi-programa.desktop y llenarlo por ejemplo con: #!/usr/bin/env xdg-open [Desktop Entry] Type=Application Name=Android Studio Exec=\"/home/javi/android-studio/bin/studio.sh\" Icon=/home/javi/android-studio/bin/studio.png Categories=Application;Programming;Android;Mobile","title":"Linux"},{"location":"informatica/linux/linux/#linux","text":"","title":"Linux"},{"location":"informatica/linux/linux/#add-to-path","text":"Permite ejecutar programas, que est\u00e9n en el directorio que a\u00f1adas, desde cualquier sitio. Editar /home/usuario/.profile y a\u00f1adir al final export PATH=$PATH:/path/to/dir Reiniciar la terminal o ejecutar source .profile","title":"Add to PATH"},{"location":"informatica/linux/linux/#crontabs","text":"crontab -l see. crontab -e edit. sudo crontab -u <username> -l other user's crontab.","title":"Crontabs"},{"location":"informatica/linux/linux/#ubuntu","text":"","title":"Ubuntu"},{"location":"informatica/linux/linux/#create-executable-for-the-ubuntu-ui","text":"Te lo encontrar\u00e1 el sistema y poder ejecutarlo con su icono y tal. Crear un archivo en /usr/share/applications y llamarlo mi-programa.desktop y llenarlo por ejemplo con: #!/usr/bin/env xdg-open [Desktop Entry] Type=Application Name=Android Studio Exec=\"/home/javi/android-studio/bin/studio.sh\" Icon=/home/javi/android-studio/bin/studio.png Categories=Application;Programming;Android;Mobile","title":"Create executable for the Ubuntu UI."},{"location":"informatica/python/cDB/","text":"Conexiones a bases de datos usando python SQLAlchemy MySQL pip install sqlachemy pip install mysqlclient Puede que necesites antes: sudo apt-get install libmysqlclient-dev sudo apt-get install python3-dev default-libmysqlclient-dev build-essential from sqlalchemy import create_engine engine = create_engine ( \"mysql+mysqldb://user:password@ip:3306/DB\" ) Postgres Los dialectos de postgres: pip install psycopg2-binary pip install psycopg2 Si sigue dando problemas (seguramente por python 3.9 no soportado) sudo apt install python3-dev libpq-dev String de conexi\u00f3n: export SQLALCHEMY_DATABASE_URI=postgresql://user:pass@ip:5432/databasename Execute statement command = \"\"\" UPDATE motit.`User` u set u.city_id = 1 where u.id in {users} \"\"\" users = tuple ( df_usuarios_zara [ 'id' ] . to_list ()) with mysql_engine . connect () as con : con . execute ( command . format ( users = users ))","title":"Conexi\u00f3n a DBs"},{"location":"informatica/python/cDB/#conexiones-a-bases-de-datos-usando-python","text":"","title":"Conexiones a bases de datos usando python"},{"location":"informatica/python/cDB/#sqlalchemy","text":"","title":"SQLAlchemy"},{"location":"informatica/python/cDB/#mysql","text":"pip install sqlachemy pip install mysqlclient Puede que necesites antes: sudo apt-get install libmysqlclient-dev sudo apt-get install python3-dev default-libmysqlclient-dev build-essential from sqlalchemy import create_engine engine = create_engine ( \"mysql+mysqldb://user:password@ip:3306/DB\" )","title":"MySQL"},{"location":"informatica/python/cDB/#postgres","text":"Los dialectos de postgres: pip install psycopg2-binary pip install psycopg2 Si sigue dando problemas (seguramente por python 3.9 no soportado) sudo apt install python3-dev libpq-dev String de conexi\u00f3n: export SQLALCHEMY_DATABASE_URI=postgresql://user:pass@ip:5432/databasename","title":"Postgres"},{"location":"informatica/python/cDB/#execute-statement","text":"command = \"\"\" UPDATE motit.`User` u set u.city_id = 1 where u.id in {users} \"\"\" users = tuple ( df_usuarios_zara [ 'id' ] . to_list ()) with mysql_engine . connect () as con : con . execute ( command . format ( users = users ))","title":"Execute statement"},{"location":"informatica/python/general/","text":"Python List comprehension if/else lista = [ f ( x ) if condition else g ( x ) for cosa in cosas ] Solo if lista = [ f ( x ) for cosa in cosas if condition ] Breakpoint con saltos de linea pip install ipython En el breakpoint poner: (pdb) from IPython import embed; embed() Conversiones de fechas Parsear str a datetime from datetime import datetime datetime_str = \"2021-01-01 00:00:00\" datetime_obj = datetime . strptime ( start_date , \"%Y-%m- %d %H:%M:%S\" ) Datetime obj a string obj_datetime = datetime ( 2021 , 1 , 1 , 0 , 0 ) str_datetime = obj_datetime . strftime ( \"%Y-%m- %d %H:%M:%S\" ) Timezones y esas cosas Convertir a timezone, le dices que timezone es y lo conviertes: date = date ( 2021 , 3 , 9 ) # ahora le pones la hora (00:00 de ese d\u00eda) date_time = datetime . combine ( date , datetime . min . time ()) # last_date a 00:00:00, tambien se puede hacer directo el datetime # le especificas y lo conviertes target_time_zone = pytz . timezone ( \"Europe/Madrid\" ) date_time . replace ( tzinfo = pytz . utc ) . astimezone ( target_time_zone ) . strftime ( ' %d -%m-%Y %H' ) # con el dia y la hora Tambien: date_interest = date ( 2021 , 3 , 28 ) # Date previous (7 days) date_interest_previous = date_interest - timedelta ( days = 7 ) local_tz = pytz . timezone ( \"Europe/Madrid\" ) # From y to de la actual date_interest_time_init = datetime . combine ( date_interest , datetime . min . time ()) # last_date a 00:00:00 date_interest_time_to = ( local_tz . localize ( date_interest_time_init . replace ( hour = hour )) . astimezone ( pytz . utc ) . replace ( tzinfo = None ) ) # From y to de la previous date_interest_time_init_previous = datetime . combine ( date_interest_previous , datetime . min . time ()) # prev a 00:00:00 date_interest_time_to_previous = ( local_tz . localize ( date_interest_time_init_previous . replace ( hour = hour )) . astimezone ( pytz . utc ) . replace ( tzinfo = None ) ) Entornos virtuales python3 -m venv path/to/newenv Might need to give execute permission: chmod +x myenv/bin/activate source myenv/bin/activate Using VirtualenvWrapper Todo esto en el entorno base! Instalar virtualenv pip install virtualenv Add to path the virtualenv to path: add to .profile the path venv was installed: export PATH=$PATH:/home/javi/.local/bin Instalar virtualenvwrapper pip install virtualenvwrapper A\u00f1adir al .bashrc export WORKON_HOME = $HOME /.virtualenvs # find / -name virtualenvwrapper.sh export VIRTUALENVWRAPPER_SCRIPT = /home/javi/.local/bin/virtualenvwrapper.sh export VIRTUALENVWRAPPER_PYTHON = /usr/bin/python3 source /home/javi/.local/bin/virtualenvwrapper.sh Binary ops Number 4 in binary with all trailing 0s format ( 4 , \"06b\" ) '000100'","title":"General"},{"location":"informatica/python/general/#python","text":"","title":"Python"},{"location":"informatica/python/general/#list-comprehension","text":"","title":"List comprehension"},{"location":"informatica/python/general/#ifelse","text":"lista = [ f ( x ) if condition else g ( x ) for cosa in cosas ]","title":"if/else"},{"location":"informatica/python/general/#solo-if","text":"lista = [ f ( x ) for cosa in cosas if condition ]","title":"Solo if"},{"location":"informatica/python/general/#breakpoint-con-saltos-de-linea","text":"pip install ipython En el breakpoint poner: (pdb) from IPython import embed; embed()","title":"Breakpoint con saltos de linea"},{"location":"informatica/python/general/#conversiones-de-fechas","text":"","title":"Conversiones de fechas"},{"location":"informatica/python/general/#parsear-str-a-datetime","text":"from datetime import datetime datetime_str = \"2021-01-01 00:00:00\" datetime_obj = datetime . strptime ( start_date , \"%Y-%m- %d %H:%M:%S\" )","title":"Parsear str a datetime"},{"location":"informatica/python/general/#datetime-obj-a-string","text":"obj_datetime = datetime ( 2021 , 1 , 1 , 0 , 0 ) str_datetime = obj_datetime . strftime ( \"%Y-%m- %d %H:%M:%S\" )","title":"Datetime obj a string"},{"location":"informatica/python/general/#timezones-y-esas-cosas","text":"Convertir a timezone, le dices que timezone es y lo conviertes: date = date ( 2021 , 3 , 9 ) # ahora le pones la hora (00:00 de ese d\u00eda) date_time = datetime . combine ( date , datetime . min . time ()) # last_date a 00:00:00, tambien se puede hacer directo el datetime # le especificas y lo conviertes target_time_zone = pytz . timezone ( \"Europe/Madrid\" ) date_time . replace ( tzinfo = pytz . utc ) . astimezone ( target_time_zone ) . strftime ( ' %d -%m-%Y %H' ) # con el dia y la hora","title":"Timezones y esas cosas"},{"location":"informatica/python/general/#tambien","text":"date_interest = date ( 2021 , 3 , 28 ) # Date previous (7 days) date_interest_previous = date_interest - timedelta ( days = 7 ) local_tz = pytz . timezone ( \"Europe/Madrid\" ) # From y to de la actual date_interest_time_init = datetime . combine ( date_interest , datetime . min . time ()) # last_date a 00:00:00 date_interest_time_to = ( local_tz . localize ( date_interest_time_init . replace ( hour = hour )) . astimezone ( pytz . utc ) . replace ( tzinfo = None ) ) # From y to de la previous date_interest_time_init_previous = datetime . combine ( date_interest_previous , datetime . min . time ()) # prev a 00:00:00 date_interest_time_to_previous = ( local_tz . localize ( date_interest_time_init_previous . replace ( hour = hour )) . astimezone ( pytz . utc ) . replace ( tzinfo = None ) )","title":"Tambien:"},{"location":"informatica/python/general/#entornos-virtuales","text":"python3 -m venv path/to/newenv Might need to give execute permission: chmod +x myenv/bin/activate source myenv/bin/activate","title":"Entornos virtuales"},{"location":"informatica/python/general/#using-virtualenvwrapper","text":"Todo esto en el entorno base! Instalar virtualenv pip install virtualenv Add to path the virtualenv to path: add to .profile the path venv was installed: export PATH=$PATH:/home/javi/.local/bin Instalar virtualenvwrapper pip install virtualenvwrapper A\u00f1adir al .bashrc export WORKON_HOME = $HOME /.virtualenvs # find / -name virtualenvwrapper.sh export VIRTUALENVWRAPPER_SCRIPT = /home/javi/.local/bin/virtualenvwrapper.sh export VIRTUALENVWRAPPER_PYTHON = /usr/bin/python3 source /home/javi/.local/bin/virtualenvwrapper.sh","title":"Using VirtualenvWrapper"},{"location":"informatica/python/general/#binary-ops","text":"Number 4 in binary with all trailing 0s format ( 4 , \"06b\" ) '000100'","title":"Binary ops"},{"location":"informatica/python/ml/","text":"Machine Learning Time Series splits Example of 5 splits, each one with a train and test sets (test set size limited) from sklearn.model_selection import TimeSeriesSplit test_size = int ( 0.05 * len ( X )) max_train_size = 300 ts_cv = TimeSeriesSplit ( n_splits = 5 , gap = 2 , # max_train_size=max_train_size, test_size = test_size , ) all_splits = list ( ts_cv . split ( X , y )) Cross validation for model performance cv_results = cross_validate ( model , X , y , cv = all_splits , # or the splitter scoring = [ \"neg_mean_absolute_error\" , \"neg_root_mean_squared_error\" , \"r2\" ], return_estimator = True ) mae = - cv_results [ \"test_neg_mean_absolute_error\" ] rmse = - cv_results [ \"test_neg_root_mean_squared_error\" ] r2 = cv_results [ \"test_r2\" ] print ( f \"CV performance: \\n \" f \"Mean Absolute Error: { mae . mean () : .3f } +/- { mae . std () : .3f } \\n \" f \"Root Mean Squared Error: { rmse . mean () : .3f } +/- { rmse . std () : .3f } \\n \" f \"R2: { r2 . mean () : .3f } +/- { r2 . std () : .3f } \\n \" ) Visualize the predictions for that cross validation The average score of the model for this method should be the same as the cross_validate def plot_predictions ( model , X , y , splits , fit = True , normalize = False , good_r2 = 0.2 ): # Each split has a Train and Test set for idx , split in enumerate ( splits ): train , test = split if fit is True : model . fit ( X . iloc [ train ], y . iloc [ train ]) model_preds = model . predict ( X . iloc [ test ]) df_test_true_pred = y . iloc [ test ] . to_frame () df_test_true_pred [ \"preds\" ] = [ p for p in model_preds ] # escalating values if normalize is True : df_test_true_pred [ \"preds\" ] = df_test_true_pred [ \"preds\" ] / y . max () df_test_true_pred [ \"revenue\" ] = df_test_true_pred [ \"revenue\" ] / y . max () mae = mean_absolute_error ( df_test_true_pred [ \"revenue\" ], df_test_true_pred [ \"preds\" ]) rmse = mean_squared_error ( df_test_true_pred [ \"revenue\" ], df_test_true_pred [ \"preds\" ]) r2 = r2_score ( df_test_true_pred [ \"revenue\" ], df_test_true_pred [ \"preds\" ]) if r2 < good_r2 : print ( f \"\u2757Low r2 for split { idx } \" ) print ( f \"For this split { idx } \\n \" f \"MAE: { mae : .3f } \\n \" f \"RMSE: { rmse : .3f } \\n \" f \"R2: { r2 : .3f } \" ) fig = px . line ( df_test_true_pred , title = f \"Predictions for test set { idx } \" ) fig . show () if fit : return model Pipelines for column transformation Apply functions to columns so it will be handled better by the model categorical_columns = [ \"season\" , \"is_covid\" ] categories = [ [ \"spring\" , \"summer\" , \"autumn\" , \"winter\" ], [ False , True ] ] # Ordinal encoder will create new columns with 0,1 values ordinal_encoder = OrdinalEncoder ( categories = categories ) xgb_pipeline = make_pipeline ( ColumnTransformer ( transformers = [ ( \"categorical\" , ordinal_encoder , categorical_columns ), ], remainder = \"passthrough\" , verbose_feature_names_out = False ), xgb . XGBRegressor () # The model ) Applying the pipeline transformers to the data matrix So it is easily accesible to the transformed data passed to the model. scaled_values = xgb_pipeline . named_steps [ \"columntransformer\" ] . fit_transform ( X ) transformed_columns = xgb_pipeline . named_steps [ \"columntransformer\" ] . get_feature_names_out () X_transformed = pd . DataFrame ( scaled_values , X . index , columns = transformed_columns ) Parameter search using a foking Pipeline Just use the named step following by __param Check the named step using pipeline.named_steps and select the key of the estimator/s (the last ones). regr = RandomForestRegressor () pipeline = make_pipeline ( ColumnTransformer ( transformers = [ ( \"categorical\" , one_hot_encoder , categorical_columns ), ( \"month_sin\" , sin_transformer ( 12 ), [ \"month\" ]), ( \"month_cos\" , cos_transformer ( 12 ), [ \"month\" ]), ], remainder = \"passthrough\" , ), regr ) n_estimators = [ int ( x ) for x in np . linspace ( start = 200 , stop = 1000 , num = 10 )] max_depth = [ int ( x ) for x in np . linspace ( 10 , 110 , num = 11 )] max_depth . append ( None ) min_samples_split = [ 2 , 5 , 10 ] min_samples_leaf = [ 1 , 2 , 4 ] bootstrap = [ True , False ] random_grid = { \"randomforestregressor__n_estimators\" : n_estimators , \"randomforestregressor__max_depth\" : max_depth , \"randomforestregressor__min_samples_split\" : min_samples_split , \"randomforestregressor__min_samples_leaf\" : min_samples_leaf , \"randomforestregressor__bootstrap\" : bootstrap , } search = RandomizedSearchCV ( pipeline , random_grid , random_state = 0 , cv = all_splits ) search . fit ( X , y ) search . best_params_ XGBoost # XGBoost param search params = { 'max_depth' : [ 3 , 5 , 6 , 10 , 15 , 20 ], 'learning_rate' : [ 0.01 , 0.1 , 0.2 , 0.3 ], 'subsample' : np . arange ( 0.5 , 1.0 , 0.1 ), 'colsample_bytree' : np . arange ( 0.4 , 1.0 , 0.1 ), 'colsample_bylevel' : np . arange ( 0.4 , 1.0 , 0.1 ), 'n_estimators' : [ 100 , 500 , 1000 ] } # Try RandomizedSearchCV for shorter computing times clf = GridSearchCV ( estimator = xgb . XGBRegressor (), param_grid = params , scoring = 'neg_mean_squared_error' , verbose = 1 , cv = all_splits ) clf . fit ( X . values , y ) print ( \"Best parameters:\" , clf . best_params_ ) print ( \"Lowest RMSE: \" , ( - clf . best_score_ ) ** ( 1 / 2.0 )) Shap Machine Learning explainability Shap with XGBoost xgb_model = xgb_model . fit ( X_transformed . values , y ) # Don't use a pipeline! first transform the data matrix explainer = shap . TreeExplainer ( xgb_model ) shap_values = explainer . shap_values ( X_transformed [ 0 :] . values ) # computing all shap values of the data (only useful if you gonna use them all) # The API is a bit crappy and the plots are very tiquismiquis def show_waterfall_plot_for ( index , max_features = 20 ): shap_object = ShapObject ( base_value = explainer . expected_value , # Baseline value values = explainer . shap_values ( X_transformed . iloc [ index : index + 1 ] . values )[ 0 ], feature_names = X_transformed . columns , data = X_transformed . iloc [ index ] # The feature values for this observation ) shap . waterfall_plot ( shap_object , max_display = max_features ) return shap_object # a very sunny day shap_obj = show_waterfall_plot_for ( 585 ); shap . force_plot ( explainer . expected_value , shap_obj . value , features = X_transformed . iloc [ 585 ])","title":"Machine Learning"},{"location":"informatica/python/ml/#machine-learning","text":"","title":"Machine Learning"},{"location":"informatica/python/ml/#time-series-splits","text":"Example of 5 splits, each one with a train and test sets (test set size limited) from sklearn.model_selection import TimeSeriesSplit test_size = int ( 0.05 * len ( X )) max_train_size = 300 ts_cv = TimeSeriesSplit ( n_splits = 5 , gap = 2 , # max_train_size=max_train_size, test_size = test_size , ) all_splits = list ( ts_cv . split ( X , y ))","title":"Time Series splits"},{"location":"informatica/python/ml/#cross-validation-for-model-performance","text":"cv_results = cross_validate ( model , X , y , cv = all_splits , # or the splitter scoring = [ \"neg_mean_absolute_error\" , \"neg_root_mean_squared_error\" , \"r2\" ], return_estimator = True ) mae = - cv_results [ \"test_neg_mean_absolute_error\" ] rmse = - cv_results [ \"test_neg_root_mean_squared_error\" ] r2 = cv_results [ \"test_r2\" ] print ( f \"CV performance: \\n \" f \"Mean Absolute Error: { mae . mean () : .3f } +/- { mae . std () : .3f } \\n \" f \"Root Mean Squared Error: { rmse . mean () : .3f } +/- { rmse . std () : .3f } \\n \" f \"R2: { r2 . mean () : .3f } +/- { r2 . std () : .3f } \\n \" )","title":"Cross validation for model performance"},{"location":"informatica/python/ml/#visualize-the-predictions-for-that-cross-validation","text":"The average score of the model for this method should be the same as the cross_validate def plot_predictions ( model , X , y , splits , fit = True , normalize = False , good_r2 = 0.2 ): # Each split has a Train and Test set for idx , split in enumerate ( splits ): train , test = split if fit is True : model . fit ( X . iloc [ train ], y . iloc [ train ]) model_preds = model . predict ( X . iloc [ test ]) df_test_true_pred = y . iloc [ test ] . to_frame () df_test_true_pred [ \"preds\" ] = [ p for p in model_preds ] # escalating values if normalize is True : df_test_true_pred [ \"preds\" ] = df_test_true_pred [ \"preds\" ] / y . max () df_test_true_pred [ \"revenue\" ] = df_test_true_pred [ \"revenue\" ] / y . max () mae = mean_absolute_error ( df_test_true_pred [ \"revenue\" ], df_test_true_pred [ \"preds\" ]) rmse = mean_squared_error ( df_test_true_pred [ \"revenue\" ], df_test_true_pred [ \"preds\" ]) r2 = r2_score ( df_test_true_pred [ \"revenue\" ], df_test_true_pred [ \"preds\" ]) if r2 < good_r2 : print ( f \"\u2757Low r2 for split { idx } \" ) print ( f \"For this split { idx } \\n \" f \"MAE: { mae : .3f } \\n \" f \"RMSE: { rmse : .3f } \\n \" f \"R2: { r2 : .3f } \" ) fig = px . line ( df_test_true_pred , title = f \"Predictions for test set { idx } \" ) fig . show () if fit : return model","title":"Visualize the predictions for that cross validation"},{"location":"informatica/python/ml/#pipelines-for-column-transformation","text":"Apply functions to columns so it will be handled better by the model categorical_columns = [ \"season\" , \"is_covid\" ] categories = [ [ \"spring\" , \"summer\" , \"autumn\" , \"winter\" ], [ False , True ] ] # Ordinal encoder will create new columns with 0,1 values ordinal_encoder = OrdinalEncoder ( categories = categories ) xgb_pipeline = make_pipeline ( ColumnTransformer ( transformers = [ ( \"categorical\" , ordinal_encoder , categorical_columns ), ], remainder = \"passthrough\" , verbose_feature_names_out = False ), xgb . XGBRegressor () # The model )","title":"Pipelines for column transformation"},{"location":"informatica/python/ml/#applying-the-pipeline-transformers-to-the-data-matrix","text":"So it is easily accesible to the transformed data passed to the model. scaled_values = xgb_pipeline . named_steps [ \"columntransformer\" ] . fit_transform ( X ) transformed_columns = xgb_pipeline . named_steps [ \"columntransformer\" ] . get_feature_names_out () X_transformed = pd . DataFrame ( scaled_values , X . index , columns = transformed_columns )","title":"Applying the pipeline transformers to the data matrix"},{"location":"informatica/python/ml/#parameter-search-using-a-foking-pipeline","text":"Just use the named step following by __param Check the named step using pipeline.named_steps and select the key of the estimator/s (the last ones). regr = RandomForestRegressor () pipeline = make_pipeline ( ColumnTransformer ( transformers = [ ( \"categorical\" , one_hot_encoder , categorical_columns ), ( \"month_sin\" , sin_transformer ( 12 ), [ \"month\" ]), ( \"month_cos\" , cos_transformer ( 12 ), [ \"month\" ]), ], remainder = \"passthrough\" , ), regr ) n_estimators = [ int ( x ) for x in np . linspace ( start = 200 , stop = 1000 , num = 10 )] max_depth = [ int ( x ) for x in np . linspace ( 10 , 110 , num = 11 )] max_depth . append ( None ) min_samples_split = [ 2 , 5 , 10 ] min_samples_leaf = [ 1 , 2 , 4 ] bootstrap = [ True , False ] random_grid = { \"randomforestregressor__n_estimators\" : n_estimators , \"randomforestregressor__max_depth\" : max_depth , \"randomforestregressor__min_samples_split\" : min_samples_split , \"randomforestregressor__min_samples_leaf\" : min_samples_leaf , \"randomforestregressor__bootstrap\" : bootstrap , } search = RandomizedSearchCV ( pipeline , random_grid , random_state = 0 , cv = all_splits ) search . fit ( X , y ) search . best_params_","title":"Parameter search using a foking Pipeline"},{"location":"informatica/python/ml/#xgboost","text":"# XGBoost param search params = { 'max_depth' : [ 3 , 5 , 6 , 10 , 15 , 20 ], 'learning_rate' : [ 0.01 , 0.1 , 0.2 , 0.3 ], 'subsample' : np . arange ( 0.5 , 1.0 , 0.1 ), 'colsample_bytree' : np . arange ( 0.4 , 1.0 , 0.1 ), 'colsample_bylevel' : np . arange ( 0.4 , 1.0 , 0.1 ), 'n_estimators' : [ 100 , 500 , 1000 ] } # Try RandomizedSearchCV for shorter computing times clf = GridSearchCV ( estimator = xgb . XGBRegressor (), param_grid = params , scoring = 'neg_mean_squared_error' , verbose = 1 , cv = all_splits ) clf . fit ( X . values , y ) print ( \"Best parameters:\" , clf . best_params_ ) print ( \"Lowest RMSE: \" , ( - clf . best_score_ ) ** ( 1 / 2.0 ))","title":"XGBoost"},{"location":"informatica/python/ml/#shap","text":"Machine Learning explainability","title":"Shap"},{"location":"informatica/python/ml/#shap-with-xgboost","text":"xgb_model = xgb_model . fit ( X_transformed . values , y ) # Don't use a pipeline! first transform the data matrix explainer = shap . TreeExplainer ( xgb_model ) shap_values = explainer . shap_values ( X_transformed [ 0 :] . values ) # computing all shap values of the data (only useful if you gonna use them all) # The API is a bit crappy and the plots are very tiquismiquis def show_waterfall_plot_for ( index , max_features = 20 ): shap_object = ShapObject ( base_value = explainer . expected_value , # Baseline value values = explainer . shap_values ( X_transformed . iloc [ index : index + 1 ] . values )[ 0 ], feature_names = X_transformed . columns , data = X_transformed . iloc [ index ] # The feature values for this observation ) shap . waterfall_plot ( shap_object , max_display = max_features ) return shap_object # a very sunny day shap_obj = show_waterfall_plot_for ( 585 ); shap . force_plot ( explainer . expected_value , shap_obj . value , features = X_transformed . iloc [ 585 ])","title":"Shap with XGBoost"},{"location":"informatica/python/pandas/","text":"Pandas Get data with NaN values df [ df . isna () . any ( axis = 1 )] Pillar un valor filtrando DF con condici\u00f3n m\u00faltiple: valor = df [( df [ \"columna_x\" ] == x ) & ( df [ \"columna_x\" ] == y )][ \"columna\" ] . iloc [ 0 ] Si vas a crear un nuevo DF, hacerlo con .copy() \u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f Para evitar el error de \"A value is trying to be set on a copy of a slice from a DataFrame.\" # df_b es un nuevo DF, sin el .copy() se guarda una vista y sale un warning si quieres meterle movidas df_b = df_mysql [ df_mysql [ \"fecha\" ] > datetime ( 2020 , 6 , 9 , 0 , 0 )] . copy () df_b [ \"deficit\" ] = df_b [ \"motos_disponibles\" ] - df_b [ \"iniciadosMySQL\" ] Take DF columns/rows by column/row index df.iloc[row,col] df_smaller = df . iloc [ 1 :,:] # from row 1 to end (skiping row 0),and all columns Devolver fila completa con valor m\u00e1ximo df . loc [ df [ 'Value' ] . idxmax ()] Hacer un count groupby y devolviendolo como DF decente df . groupby ([ 'col1' , 'col2' ]) . size () . reset_index ( name = 'counts' ) Aplicar funci\u00f3n custom para DF usando Lambda A\u00f1ade un nuevo campo al dataframe dependiendo de una condici\u00f3n calculada por funci\u00f3n. Con list comprehension no se pueden utilizar funciones custom. Se puede acceder al campo de la fila ya sea con row[\"campo\"] o row.campo df [ \"mov\" ] = df . apply ( lambda row : False if viaje_terminado_cerca ( row [ \"pos_init\" ], row . pos_fin ) else True , axis = 1 ) Con esto podr\u00edas filtrar las nuevas filas que no hayan terminado cerca (movimiento = true) df = df [ df [ \"mov\" ] == True ] Aplicar funci\u00f3n a un \u00edndice Como el df.apply pero para aplicarselo al \u00edndice (si por ejemplo tienes una fecha como \u00edndice). df_serie [ \"week_day\" ] = df_serie . index . map ( lambda fecha : fecha . weekday ()) Apply filter to some values Example case you want to replace 0s for a new value. mask = df [ \"columna\" ] == 0 df . loc [ mask , \"columna\" ] = new_value Column with list to rows You have the next df: user items 0 1 101 1 2 [102, 103] df . explode ( \"items\" ) And you get: user items 0 1 101 1 2 102 1 2 103 Rows to columns using unstack You have this DF # Group by the columns df = df . groupby ([ \"race\" , \"age\" ]) . size () df race age African-American 18 2 19 22 20 109 21 191 22 187 ... Other 63 1 64 1 66 1 69 2 70 1 Length: 263, dtype: int64 Then do a unstack df = df . unstack ( \"race\" ) . reset_index () . fillna ( 0 ) df . head () GeoPandas Create a uniform square grid within a bounding box import geopandas as gpd from math import cos , pi import numpy as np def delta_coords ( coords : list , m_north , m_east ): \"\"\" Calculates the new coordinates values based on the displacement North and East in meters. Params: coords (list): list containing initial point [lat, long] m_north, m_east: displacement in each direction in meters Returns: latO, longO: The new values after the displacement. \"\"\" #Position, decimal degrees lat = coords [ 0 ] long = coords [ 1 ] #Earth\u2019s radius, sphere R = 6378137 # //offsets in meters dn = m_north de = m_east # //Coordinate offsets in radians dLat = dn / R dLon = de / ( R * cos ( pi * lat / 180 )) # //OffsetPosition, decimal degrees latO = lat + dLat * 180 / pi lonO = long + dLon * 180 / pi return latO , lonO def get_grid ( bbox : list , meters ) -> gpd . GeoDataFrame : \"\"\" bounding_box: [min_lat, min_long, max_lat, max_long] Returns a GeoDf with a square grid of meters within the bbox. \"\"\" min_lat = bbox [ 0 ] max_lat = bbox [ 2 ] min_long = bbox [ 1 ] max_long = bbox [ 3 ] # Getting the delta coords for every x meters displaced using a point of the bbox # To the east (longitude) step_east = delta_coords ( [ min_lat , min_long ], 0 , meters ) step_east = step_east [ 1 ] - min_long # To the north step_north = delta_coords ( [ min_lat , min_long ], meters , 0 ) step_north = step_north [ 0 ] - min_lat new_longs = np . arange ( min_long , max_long + step_east , step_east ) new_lats = np . arange ( min_lat , max_lat + step_north , step_north ) polygons = [] for lat in new_lats : for long in new_longs : polygons . append ( Polygon ( [ [ long , lat ], [ long + step_east , lat ], [ long + step_east , lat + step_north ], [ long , lat + step_north ], ] ) ) grid = gpd . GeoDataFrame ({ \"geometry\" : polygons }, crs = \"EPSG:4326\" ) grid [ \"id\" ] = [ i for i in range ( len ( grid ))] return grid grid = get_grid ([ 55.554479 , 12.344015 , 55.809976 , 12.714631 ], 100 ) Create GeoDF prepared to do operations geo_series = gpd . points_from_xy ( rentals_df [ 'longitude_start' ], rentals_df [ 'latitude_start' ]) rentals_df = gpd . GeoDataFrame ( rentals_df , geometry = geo_series , crs = 'EPSG:4326' ) Spatial join counting points inside polygons # sjoin returns a row for each point inside the polygon - [polygon_x, point_p] sjoin = gpd . sjoin ( grid , points ) # Grouping by polygon to count amount of points inside them sjoin = sjoin . groupby ( \"id_left\" ) . size () . reset_index ( name = \"count\" ) . \\ sort_values ( by = \"count\" , ascending = False ) . rename ( columns = { \"id_left\" : \"grid_id\" }) # getting those polygons with at least a point in them grid_with_points = grid . merge ( sjoin , left_on = \"id\" , right_on = \"grid_id\" )","title":"Pandas"},{"location":"informatica/python/pandas/#pandas","text":"","title":"Pandas"},{"location":"informatica/python/pandas/#get-data-with-nan-values","text":"df [ df . isna () . any ( axis = 1 )]","title":"Get data with NaN values"},{"location":"informatica/python/pandas/#pillar-un-valor-filtrando-df-con-condicion-multiple","text":"valor = df [( df [ \"columna_x\" ] == x ) & ( df [ \"columna_x\" ] == y )][ \"columna\" ] . iloc [ 0 ]","title":"Pillar un valor filtrando DF con condici\u00f3n m\u00faltiple:"},{"location":"informatica/python/pandas/#si-vas-a-crear-un-nuevo-df-hacerlo-con-copy","text":"Para evitar el error de \"A value is trying to be set on a copy of a slice from a DataFrame.\" # df_b es un nuevo DF, sin el .copy() se guarda una vista y sale un warning si quieres meterle movidas df_b = df_mysql [ df_mysql [ \"fecha\" ] > datetime ( 2020 , 6 , 9 , 0 , 0 )] . copy () df_b [ \"deficit\" ] = df_b [ \"motos_disponibles\" ] - df_b [ \"iniciadosMySQL\" ]","title":"Si vas a crear un nuevo DF, hacerlo con .copy() \u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f"},{"location":"informatica/python/pandas/#take-df-columnsrows-by-columnrow-index","text":"df.iloc[row,col] df_smaller = df . iloc [ 1 :,:] # from row 1 to end (skiping row 0),and all columns","title":"Take DF columns/rows by column/row index"},{"location":"informatica/python/pandas/#devolver-fila-completa-con-valor-maximo","text":"df . loc [ df [ 'Value' ] . idxmax ()]","title":"Devolver fila completa con valor m\u00e1ximo"},{"location":"informatica/python/pandas/#hacer-un-count-groupby-y-devolviendolo-como-df-decente","text":"df . groupby ([ 'col1' , 'col2' ]) . size () . reset_index ( name = 'counts' )","title":"Hacer un count groupby y devolviendolo como DF decente"},{"location":"informatica/python/pandas/#aplicar-funcion-custom-para-df-usando-lambda","text":"A\u00f1ade un nuevo campo al dataframe dependiendo de una condici\u00f3n calculada por funci\u00f3n. Con list comprehension no se pueden utilizar funciones custom. Se puede acceder al campo de la fila ya sea con row[\"campo\"] o row.campo df [ \"mov\" ] = df . apply ( lambda row : False if viaje_terminado_cerca ( row [ \"pos_init\" ], row . pos_fin ) else True , axis = 1 ) Con esto podr\u00edas filtrar las nuevas filas que no hayan terminado cerca (movimiento = true) df = df [ df [ \"mov\" ] == True ]","title":"Aplicar funci\u00f3n custom para DF usando Lambda"},{"location":"informatica/python/pandas/#aplicar-funcion-a-un-indice","text":"Como el df.apply pero para aplicarselo al \u00edndice (si por ejemplo tienes una fecha como \u00edndice). df_serie [ \"week_day\" ] = df_serie . index . map ( lambda fecha : fecha . weekday ())","title":"Aplicar funci\u00f3n a un \u00edndice"},{"location":"informatica/python/pandas/#apply-filter-to-some-values","text":"Example case you want to replace 0s for a new value. mask = df [ \"columna\" ] == 0 df . loc [ mask , \"columna\" ] = new_value","title":"Apply filter to some values"},{"location":"informatica/python/pandas/#column-with-list-to-rows","text":"You have the next df: user items 0 1 101 1 2 [102, 103] df . explode ( \"items\" ) And you get: user items 0 1 101 1 2 102 1 2 103","title":"Column with list to rows"},{"location":"informatica/python/pandas/#rows-to-columns-using-unstack","text":"You have this DF # Group by the columns df = df . groupby ([ \"race\" , \"age\" ]) . size () df race age African-American 18 2 19 22 20 109 21 191 22 187 ... Other 63 1 64 1 66 1 69 2 70 1 Length: 263, dtype: int64 Then do a unstack df = df . unstack ( \"race\" ) . reset_index () . fillna ( 0 ) df . head ()","title":"Rows to columns using unstack"},{"location":"informatica/python/pandas/#geopandas","text":"","title":"GeoPandas"},{"location":"informatica/python/pandas/#create-a-uniform-square-grid-within-a-bounding-box","text":"import geopandas as gpd from math import cos , pi import numpy as np def delta_coords ( coords : list , m_north , m_east ): \"\"\" Calculates the new coordinates values based on the displacement North and East in meters. Params: coords (list): list containing initial point [lat, long] m_north, m_east: displacement in each direction in meters Returns: latO, longO: The new values after the displacement. \"\"\" #Position, decimal degrees lat = coords [ 0 ] long = coords [ 1 ] #Earth\u2019s radius, sphere R = 6378137 # //offsets in meters dn = m_north de = m_east # //Coordinate offsets in radians dLat = dn / R dLon = de / ( R * cos ( pi * lat / 180 )) # //OffsetPosition, decimal degrees latO = lat + dLat * 180 / pi lonO = long + dLon * 180 / pi return latO , lonO def get_grid ( bbox : list , meters ) -> gpd . GeoDataFrame : \"\"\" bounding_box: [min_lat, min_long, max_lat, max_long] Returns a GeoDf with a square grid of meters within the bbox. \"\"\" min_lat = bbox [ 0 ] max_lat = bbox [ 2 ] min_long = bbox [ 1 ] max_long = bbox [ 3 ] # Getting the delta coords for every x meters displaced using a point of the bbox # To the east (longitude) step_east = delta_coords ( [ min_lat , min_long ], 0 , meters ) step_east = step_east [ 1 ] - min_long # To the north step_north = delta_coords ( [ min_lat , min_long ], meters , 0 ) step_north = step_north [ 0 ] - min_lat new_longs = np . arange ( min_long , max_long + step_east , step_east ) new_lats = np . arange ( min_lat , max_lat + step_north , step_north ) polygons = [] for lat in new_lats : for long in new_longs : polygons . append ( Polygon ( [ [ long , lat ], [ long + step_east , lat ], [ long + step_east , lat + step_north ], [ long , lat + step_north ], ] ) ) grid = gpd . GeoDataFrame ({ \"geometry\" : polygons }, crs = \"EPSG:4326\" ) grid [ \"id\" ] = [ i for i in range ( len ( grid ))] return grid grid = get_grid ([ 55.554479 , 12.344015 , 55.809976 , 12.714631 ], 100 )","title":"Create a uniform square grid within a bounding box"},{"location":"informatica/python/pandas/#create-geodf-prepared-to-do-operations","text":"geo_series = gpd . points_from_xy ( rentals_df [ 'longitude_start' ], rentals_df [ 'latitude_start' ]) rentals_df = gpd . GeoDataFrame ( rentals_df , geometry = geo_series , crs = 'EPSG:4326' )","title":"Create GeoDF prepared to do operations"},{"location":"informatica/python/pandas/#spatial-join-counting-points-inside-polygons","text":"# sjoin returns a row for each point inside the polygon - [polygon_x, point_p] sjoin = gpd . sjoin ( grid , points ) # Grouping by polygon to count amount of points inside them sjoin = sjoin . groupby ( \"id_left\" ) . size () . reset_index ( name = \"count\" ) . \\ sort_values ( by = \"count\" , ascending = False ) . rename ( columns = { \"id_left\" : \"grid_id\" }) # getting those polygons with at least a point in them grid_with_points = grid . merge ( sjoin , left_on = \"id\" , right_on = \"grid_id\" )","title":"Spatial join counting points inside polygons"},{"location":"informatica/python/plots/","text":"Matplotlib Subfigures Matplotlib fig , axs = plt . subplots ( n_rows , n_cols , sharex = True , sharey = True , figsize = ( 15 , 15 )) for idx , face in enumerate ( eigenfaces [: n_rows * n_cols ]): axs [ idx // n_rows , idx % n_cols ] . plot ( your_data ) Plotly Crear figura con multiples l\u00edneas import plotly.express as px import pandas as pd df = pd . read_csv ( \"data/serie_atocha_crudo.csv\" ) # columnas = fecha, motos_disponibles, iniciados, finalizados fig = px . line ( df , x = \"fecha\" , y = [ \"motos_disponibles\" , \"iniciados\" ], width = 2200 , height = 1000 , title = \"layout.hovermode='x'\" ) fig . update_layout ( hovermode = \"x\" ) # para que al pasar el cursor te muestre ambos valores fig . show () Figure with multiple lines from different dfs and vetical line with annotation import plotly.graph_objects as go import plotly.express as px fig1 = px . line ( title = \"Ratings por tema en n\u00fameros absolutos\" ) fig1 . add_trace ( go . Scatter ( x = quejas [ 'fecha' ], y = quejas [ \"counts_\" ], name = \"name\" , #line = dict(color=colors[i]), mode = \"lines\" ) ) fig1 . add_trace ( go . Scatter ( x = df_count_posneg [ 'date_trunc' ], y = df_count_posneg [ \"count_negativos\" ], name = \"negativos (<= 3 estrellas)\" , line = dict ( color = \"red\" , width = 1 , dash = 'dash' ), mode = \"lines\" #dash=\"dash\" ) ) fig1 . add_trace ( go . Scatter ( x = df_count_posneg [ 'date_trunc' ], y = df_count_posneg [ \"count_positivos\" ], name = \"positivos (> 3 estrellas)\" , line = dict ( color = \"green\" , width = 1 , dash = 'dash' ), mode = \"lines\" #dash=\"dash\" ) ) fig1 . add_annotation ( x = \"2021-05-01\" , y = 20000 , text = \"Ratings pasan de 3 a 5 estrellas\" , showarrow = True , arrowhead = 1 ) fig1 . add_vline ( x = \"2021-05-01\" , line_width = 0.5 ) #, x1=2) fig1 . show () Histogram when Y axis is already computed Use px.bar() px.histogram() won\u00b4t work because it will try to count the Y axis again lmao. fecha finalizados 0 2021-10-06 00:00:00 2 1 2021-10-07 00:00:00 39 2 2021-10-08 00:00:00 63 3 2021-10-09 00:00:00 44 4 2021-10-10 00:00:00 60 fig = px . bar ( finalizados_dias_df , x = \"fecha\" , y = \"finalizados\" ) fig . show () Folium Create a Choropleth or Grid map with tooltip m = folium . Map ( location = [ 55.6829 , 12.5775 ], zoom_start = 11 , tiles = \"cartodbpositron\" ) folium . Choropleth ( geo_data = grid_with_rentals , # GeoDataFrame fill_color = \"RdPu\" , data = grid_with_rentals , columns = [ \"id\" , \"count_log\" ], # id of the grid, count key_on = 'feature.properties.id' , # id of the grid line_opacity = 1 , line_weight = 0.1 ) . add_to ( m ) # Tooltips style = { 'fillColor' : '#00000000' , 'color' : '#00000000' } feature = folium . features . GeoJson ( grid_with_rentals , name = 'count' , # Column to show the data of each grid style_function = lambda x : style , tooltip = folium . GeoJsonTooltip ( fields = [ \"count\" ], aliases = [ \"count\" ], labels = True )) m . add_child ( feature ) Add elements to different layer so they can be deselected Just create a FeatureGroup and add stuff to it means_group = folium . FeatureGroup ( name = \"Centroids\" ) . add_to ( m ) # Adding markers to the FeatureGroup [ means_group . add_child ( folium . Marker ( mean , popup = \"Cluster center\" )) for mean in means ] folium . LayerControl () . add_to ( m )","title":"Plots"},{"location":"informatica/python/plots/#matplotlib","text":"","title":"Matplotlib"},{"location":"informatica/python/plots/#subfigures-matplotlib","text":"fig , axs = plt . subplots ( n_rows , n_cols , sharex = True , sharey = True , figsize = ( 15 , 15 )) for idx , face in enumerate ( eigenfaces [: n_rows * n_cols ]): axs [ idx // n_rows , idx % n_cols ] . plot ( your_data )","title":"Subfigures Matplotlib"},{"location":"informatica/python/plots/#plotly","text":"","title":"Plotly"},{"location":"informatica/python/plots/#crear-figura-con-multiples-lineas","text":"import plotly.express as px import pandas as pd df = pd . read_csv ( \"data/serie_atocha_crudo.csv\" ) # columnas = fecha, motos_disponibles, iniciados, finalizados fig = px . line ( df , x = \"fecha\" , y = [ \"motos_disponibles\" , \"iniciados\" ], width = 2200 , height = 1000 , title = \"layout.hovermode='x'\" ) fig . update_layout ( hovermode = \"x\" ) # para que al pasar el cursor te muestre ambos valores fig . show ()","title":"Crear figura con multiples l\u00edneas"},{"location":"informatica/python/plots/#figure-with-multiple-lines-from-different-dfs-and-vetical-line-with-annotation","text":"import plotly.graph_objects as go import plotly.express as px fig1 = px . line ( title = \"Ratings por tema en n\u00fameros absolutos\" ) fig1 . add_trace ( go . Scatter ( x = quejas [ 'fecha' ], y = quejas [ \"counts_\" ], name = \"name\" , #line = dict(color=colors[i]), mode = \"lines\" ) ) fig1 . add_trace ( go . Scatter ( x = df_count_posneg [ 'date_trunc' ], y = df_count_posneg [ \"count_negativos\" ], name = \"negativos (<= 3 estrellas)\" , line = dict ( color = \"red\" , width = 1 , dash = 'dash' ), mode = \"lines\" #dash=\"dash\" ) ) fig1 . add_trace ( go . Scatter ( x = df_count_posneg [ 'date_trunc' ], y = df_count_posneg [ \"count_positivos\" ], name = \"positivos (> 3 estrellas)\" , line = dict ( color = \"green\" , width = 1 , dash = 'dash' ), mode = \"lines\" #dash=\"dash\" ) ) fig1 . add_annotation ( x = \"2021-05-01\" , y = 20000 , text = \"Ratings pasan de 3 a 5 estrellas\" , showarrow = True , arrowhead = 1 ) fig1 . add_vline ( x = \"2021-05-01\" , line_width = 0.5 ) #, x1=2) fig1 . show ()","title":"Figure with multiple lines from different dfs and vetical line with annotation"},{"location":"informatica/python/plots/#histogram-when-y-axis-is-already-computed","text":"Use px.bar() px.histogram() won\u00b4t work because it will try to count the Y axis again lmao. fecha finalizados 0 2021-10-06 00:00:00 2 1 2021-10-07 00:00:00 39 2 2021-10-08 00:00:00 63 3 2021-10-09 00:00:00 44 4 2021-10-10 00:00:00 60 fig = px . bar ( finalizados_dias_df , x = \"fecha\" , y = \"finalizados\" ) fig . show ()","title":"Histogram when Y axis is already computed"},{"location":"informatica/python/plots/#folium","text":"","title":"Folium"},{"location":"informatica/python/plots/#create-a-choropleth-or-grid-map-with-tooltip","text":"m = folium . Map ( location = [ 55.6829 , 12.5775 ], zoom_start = 11 , tiles = \"cartodbpositron\" ) folium . Choropleth ( geo_data = grid_with_rentals , # GeoDataFrame fill_color = \"RdPu\" , data = grid_with_rentals , columns = [ \"id\" , \"count_log\" ], # id of the grid, count key_on = 'feature.properties.id' , # id of the grid line_opacity = 1 , line_weight = 0.1 ) . add_to ( m ) # Tooltips style = { 'fillColor' : '#00000000' , 'color' : '#00000000' } feature = folium . features . GeoJson ( grid_with_rentals , name = 'count' , # Column to show the data of each grid style_function = lambda x : style , tooltip = folium . GeoJsonTooltip ( fields = [ \"count\" ], aliases = [ \"count\" ], labels = True )) m . add_child ( feature )","title":"Create a Choropleth or Grid map with tooltip"},{"location":"informatica/python/plots/#add-elements-to-different-layer-so-they-can-be-deselected","text":"Just create a FeatureGroup and add stuff to it means_group = folium . FeatureGroup ( name = \"Centroids\" ) . add_to ( m ) # Adding markers to the FeatureGroup [ means_group . add_child ( folium . Marker ( mean , popup = \"Cluster center\" )) for mean in means ] folium . LayerControl () . add_to ( m )","title":"Add elements to different layer so they can be deselected"}]}